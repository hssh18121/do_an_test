{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work2/Workspace/sonnh/do_an_test/mobilenetv3-tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 18:45:38.554691: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-19 18:45:38.574366: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-19 18:45:38.574391: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-19 18:45:38.574401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-19 18:45:38.578171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %cd \"Upernet\"\n",
    "%cd \"mobilenetv3-tensorflow\"\n",
    "from mobilenetv3_factory import build_mobilenetv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from patchify import patchify\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.math import log , reduce_mean\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_image_dataset_path = '../bk-isut-dataset/train_image_dataset.npy'\n",
    "save_val_image_dataset_path = '../bk-isut-dataset/val_image_dataset.npy'\n",
    "save_test_image_dataset_path = '../bk-isut-dataset/test_image_dataset.npy'\n",
    "save_train_mask_image_dataset_path = '../bk-isut-dataset/mask_train_image_dataset.npy'\n",
    "save_val_mask_image_dataset_path = '../bk-isut-dataset/mask_val_image_dataset.npy'\n",
    "save_test_mask_image_dataset_path = '../bk-isut-dataset/mask_test_image_dataset.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(save_train_image_dataset_path, mmap_mode='c')\n",
    "X_val = np.load(save_val_image_dataset_path, mmap_mode='c')\n",
    "X_test = np.load(save_test_image_dataset_path, mmap_mode='c')\n",
    "y_train = np.load(save_train_mask_image_dataset_path, mmap_mode='c')\n",
    "y_val = np.load(save_val_mask_image_dataset_path, mmap_mode='c')\n",
    "y_test = np.load(save_test_mask_image_dataset_path, mmap_mode='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.9 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" \n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation function\n",
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "def get_training_augmentation(height, width):\n",
    "    train_transform = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(scale_limit=0.6, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0, value=0),\n",
    "        A.PadIfNeeded(min_height=height, min_width=width, always_apply=True, border_mode=0, value=0),\n",
    "        A.RandomCrop(height=height, width=width, always_apply=True),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.Perspective(p=0.5),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightnessContrast(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Sharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply augmentation\n",
    "def augment_data(image, mask):\n",
    "    aug = get_training_augmentation(256, 256)(image=image, mask=mask)\n",
    "    aug_image = aug['image'].astype(np.uint8)\n",
    "    aug_mask = aug['mask'].astype(np.uint8)\n",
    "    return aug_image, aug_mask\n",
    "\n",
    "# Wrap the augmentation function for TensorFlow\n",
    "def tf_augment_data(image, mask):\n",
    "    aug_img, aug_mask = tf.numpy_function(func=augment_data, inp=[image, mask], Tout=[tf.uint8, tf.uint8])\n",
    "    return aug_img, aug_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 18:45:48.912805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.927585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.927685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.929387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.929454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.929494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.983075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.983164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.983220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 18:45:48.983317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1018 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-06-19 18:46:00.826529: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 973.12MiB (rounded to 1020395520)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-06-19 18:46:00.827523: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-06-19 18:46:00.827567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827579: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827599: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827610: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827619: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827629: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827638: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827647: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827657: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827666: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827676: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827685: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827694: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827703: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827713: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827722: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827731: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827741: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827750: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827760: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827801: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 1018.00MiB allocated for chunks. 583.88MiB in use in bin. 583.88MiB client-requested in use in bin.\n",
      "2024-06-19 18:46:00.827815: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 973.12MiB was 256.00MiB, Chunk State: \n",
      "2024-06-19 18:46:00.827848: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 434.12MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1.2KiB | Requested Size: 1.0KiB | in_use: 1 | bin_num: -1\n",
      "2024-06-19 18:46:00.827857: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1067450368\n",
      "2024-06-19 18:46:00.827869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fd7b4000000 of size 612237312 next 1\n",
      "2024-06-19 18:46:00.827878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fd7d87e0000 of size 1280 next 2\n",
      "2024-06-19 18:46:00.827887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fd7d87e0500 of size 455211776 next 18446744073709551615\n",
      "2024-06-19 18:46:00.827895: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-06-19 18:46:00.827906: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-06-19 18:46:00.827915: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 612237312 totalling 583.88MiB\n",
      "2024-06-19 18:46:00.827924: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 583.88MiB\n",
      "2024-06-19 18:46:00.827934: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 1067450368 memory_limit_: 1067450368 available bytes: 0 curr_region_allocation_bytes_: 2134900736\n",
      "2024-06-19 18:46:00.827949: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      1067450368\n",
      "InUse:                       612238592\n",
      "MaxInUse:                    612238592\n",
      "NumAllocs:                           2\n",
      "MaxAllocSize:                612237312\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-06-19 18:46:00.827960: W tensorflow/tsl/framework/bfc_allocator.cc:497] **********************************************************__________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:105\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:514\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    511\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    515\u001b[0m     element,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for [[[[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  ...\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]]\n\n\n [[[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  ...\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]]\n\n\n [[[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  ...\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]]\n\n\n ...\n\n\n [[[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  ...\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]]\n\n\n [[[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  [[1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   ...\n   [1 0 0 0 0]\n   [1 0 0 0 0]\n   [1 0 0 0 0]]\n\n  ...\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]]\n\n\n [[[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  ...\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]\n\n  [[0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   ...\n   [0 1 0 0 0]\n   [0 1 0 0 0]\n   [0 1 0 0 0]]]] with type memmap",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((X_val, y_val))\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:821\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:110\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 110\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:698\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    697\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:328\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    327\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 328\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniforge3/envs/sonnh/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(X_batch, y_batch):\n",
    "  X_batch = tf.cast(X_batch, tf.float32)\n",
    "  y_batch = tf.cast(y_batch, tf.float32)\n",
    "  return X_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and batch the datasets\n",
    "train_dataset = train_dataset.map(_normalize).batch(16)\n",
    "val_dataset = val_dataset.batch(16).map(_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./weights/augmented_mobilenet/cp.weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE1 = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "# preprocess input\n",
    "train_dataset = preprocess_input(train_dataset)\n",
    "val_dataset = preprocess_input(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mobilenetv3(\"small\",\n",
    "    input_shape=(256, 256, 3),\n",
    "    num_classes=5,\n",
    ")\n",
    "\n",
    "total_loss = sm.losses.dice_loss + 2 * sm.losses.focal_loss\n",
    "model.compile('Adam', loss=total_loss, metrics=[sm.metrics.iou_score],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_loss'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                             monitor='val_loss',\n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=True,\n",
    "                                             verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "# model = tf.keras.models.load_model('my_model_with_batch_image.keras')\n",
    "history = model.fit(\n",
    "   train_dataset,\n",
    "   epochs=200,\n",
    "   validation_data=val_dataset,\n",
    "   callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sonnh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
