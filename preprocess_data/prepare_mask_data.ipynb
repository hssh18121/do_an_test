{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./crop_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 19:49:40.321554: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-22 19:49:40.505732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 19:49:40.505762: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 19:49:40.507616: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 19:49:40.617867: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36349\n"
     ]
    }
   ],
   "source": [
    "number_of_mask = 0\n",
    "mask_train_dataset = []\n",
    "mask_val_dataset = []\n",
    "for folder_name in sorted(os.listdir(output_path)):  # Ensure folders are iterated in sorted order\n",
    "    folder_path = os.path.join(output_path, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name=='train':\n",
    "        for image_folder_name in sorted(os.listdir(folder_path)):  # Sort subfolders as well\n",
    "            image_folder_path = os.path.join(folder_path, image_folder_name)\n",
    "            # print(image_folder_path)\n",
    "            if 'combined_mask' in image_folder_path:\n",
    "                for image_name in sorted(os.listdir(image_folder_path)):  # Sort image filenames\n",
    "                    image_path = os.path.join(image_folder_path, image_name)\n",
    "                    img = cv2.imread(image_path, 1)\n",
    "                    mask_train_dataset.append(img)\n",
    "                    number_of_mask += 1\n",
    "\n",
    "    if os.path.isdir(folder_path) and folder_name=='val':\n",
    "        for image_folder_name in sorted(os.listdir(folder_path)):  # Sort subfolders as well\n",
    "            image_folder_path = os.path.join(folder_path, image_folder_name)\n",
    "            # print(image_folder_path)\n",
    "            if 'combined_mask' in image_folder_path:\n",
    "                for image_name in sorted(os.listdir(image_folder_path)):  # Sort image filenames\n",
    "                    image_path = os.path.join(image_folder_path, image_name)\n",
    "                    img = cv2.imread(image_path, 1)\n",
    "                    mask_val_dataset.append(img)\n",
    "                    number_of_mask += 1\n",
    "\n",
    "print(number_of_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_dataset = np.array(mask_train_dataset)\n",
    "mask_val_dataset = np.array(mask_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_dataset = np.mean(mask_train_dataset, axis=-1, dtype=np.uint8, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31154, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(mask_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_val_dataset = np.mean(mask_val_dataset, axis=-1, dtype=np.uint8, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5195, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(mask_val_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_mask_image_dataset_path = './save_data_path/mask_train_image_dataset.npy'\n",
    "save_val_mask_image_dataset_path = './save_data_path/mask_val_image_dataset.npy'\n",
    "\n",
    "save_mask_chunk1_path = 'save_data_path/mask_chunk1.npy'\n",
    "save_mask_chunk2_path = 'save_data_path/mask_chunk2.npy'\n",
    "save_mask_chunk3_path = 'save_data_path/mask_chunk3.npy'\n",
    "save_mask_chunk4_path = 'save_data_path/mask_chunk4.npy'\n",
    "save_mask_chunk5_path = 'save_data_path/mask_chunk5.npy'\n",
    "save_mask_chunk6_path = 'save_data_path/mask_chunk6.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./save_data_path', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "temp1 = to_categorical(mask_train_dataset[0:5000], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk1_path, temp1)\n",
    "del temp1\n",
    "\n",
    "temp2 = to_categorical(mask_train_dataset[5000:10000], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk2_path, temp2)\n",
    "del temp2\n",
    "\n",
    "temp3 = to_categorical(mask_train_dataset[10000:15000], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk3_path, temp3)\n",
    "del temp3\n",
    "\n",
    "temp4 = to_categorical(mask_train_dataset[15000:20000], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk4_path, temp4)\n",
    "del temp4\n",
    "\n",
    "temp5 = to_categorical(mask_train_dataset[20000:25000], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk5_path, temp5)\n",
    "del temp5\n",
    "\n",
    "temp6 = to_categorical(mask_train_dataset[25000:], dtype=\"uint8\")\n",
    "np.save(save_mask_chunk6_path, temp6)\n",
    "del temp6\n",
    "\n",
    "temp1 = np.load(save_mask_chunk1_path, mmap_mode='c')\n",
    "temp2 = np.load(save_mask_chunk2_path, mmap_mode='c')\n",
    "temp3 = np.load(save_mask_chunk3_path, mmap_mode='c')\n",
    "temp4 = np.load(save_mask_chunk4_path, mmap_mode='c')\n",
    "temp5 = np.load(save_mask_chunk5_path, mmap_mode='c')\n",
    "temp6 = np.load(save_mask_chunk6_path, mmap_mode='c')\n",
    "\n",
    "mask_train_dataset = np.concatenate((temp1, temp2, temp3, temp4, temp5, temp6), axis=0)\n",
    "np.save(save_train_mask_image_dataset_path, mask_train_dataset)\n",
    "\n",
    "print(mask_train_dataset.shape)\n",
    "\n",
    "del mask_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_val_dataset = to_categorical(mask_val_dataset, dtype=\"uint8\")\n",
    "\n",
    "np.save(save_val_mask_image_dataset_path, mask_val_dataset)\n",
    "\n",
    "del mask_val_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sonnh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
